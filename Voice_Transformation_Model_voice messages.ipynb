{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "P-TrH9ZO3ao5",
    "outputId": "e3df32d5-b475-4e26-8489-1f9814b34d86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition\n",
      "  Downloading SpeechRecognition-3.10.3-py2.py3-none-any.whl.metadata (29 kB)\n",
      "Collecting googletrans\n",
      "  Downloading googletrans-3.0.0.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting datasets\n",
      "  Downloading datasets-2.19.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting soundfile\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl.metadata (14 kB)\n",
      "Collecting speechbrain\n",
      "  Downloading speechbrain-1.0.0-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.31.0)\n",
      "Requirement already satisfied: BeautifulSoup4 in /opt/conda/lib/python3.10/site-packages (4.12.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from SpeechRecognition) (4.9.0)\n",
      "Collecting httpx==0.13.3 (from googletrans)\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans) (2023.11.17)\n",
      "Collecting hstspreload (from httpx==0.13.3->googletrans)\n",
      "  Downloading hstspreload-2024.5.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans) (1.3.1)\n",
      "Collecting chardet==3.* (from httpx==0.13.3->googletrans)\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting idna==2.* (from httpx==0.13.3->googletrans)\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans)\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans)\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.3)\n",
      "Collecting pyarrow>=12.0.0 (from datasets)\n",
      "  Downloading pyarrow-16.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.65.0)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2023.12.2)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile) (1.16.0)\n",
      "Collecting hyperpyyaml (from speechbrain)\n",
      "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting joblib (from speechbrain)\n",
      "  Downloading joblib-1.4.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting scipy (from speechbrain)\n",
      "  Downloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece (from speechbrain)\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: torch>=1.9 in /opt/conda/lib/python3.10/site-packages (from speechbrain) (2.2.0)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (from speechbrain) (2.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.18)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from BeautifulSoup4) (2.5)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (3.1.2)\n",
      "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain)\n",
      "  Downloading ruamel.yaml-0.18.6-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain)\n",
      "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9->speechbrain) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9->speechbrain) (1.3.0)\n",
      "Downloading SpeechRecognition-3.10.3-py2.py3-none-any.whl (32.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.19.0-py3-none-any.whl (542 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading speechbrain-1.0.0-py3-none-any.whl (760 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.1/760.1 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-16.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
      "Downloading joblib-1.4.0-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.2/301.2 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Downloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hstspreload-2024.5.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for googletrans: filename=googletrans-3.0.0-py3-none-any.whl size=15716 sha256=02d93db7c5c252e3229d7e8bd3233c1bc1b73aab8172905bc1882170a4924d9f\n",
      "  Stored in directory: /root/.cache/pip/wheels/b3/81/ea/8b030407f8ebfc2f857814e086bb22ca2d4fea1a7be63652ab\n",
      "Successfully built googletrans\n",
      "Installing collected packages: sentencepiece, rfc3986, hyperframe, hpack, h11, chardet, xxhash, tzdata, scipy, ruamel.yaml.clib, pyarrow-hotfix, pyarrow, multidict, joblib, idna, hstspreload, h2, frozenlist, dill, async-timeout, yarl, soundfile, ruamel.yaml, pandas, multiprocess, httpcore, aiosignal, SpeechRecognition, hyperpyyaml, huggingface-hub, httpx, aiohttp, speechbrain, googletrans, datasets\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.14.0\n",
      "    Uninstalling h11-0.14.0:\n",
      "      Successfully uninstalled h11-0.14.0\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 4.0.0\n",
      "    Uninstalling chardet-4.0.0:\n",
      "      Successfully uninstalled chardet-4.0.0\n",
      "  Attempting uninstall: ruamel.yaml.clib\n",
      "    Found existing installation: ruamel.yaml.clib 0.2.6\n",
      "    Uninstalling ruamel.yaml.clib-0.2.6:\n",
      "      Successfully uninstalled ruamel.yaml.clib-0.2.6\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "  Attempting uninstall: ruamel.yaml\n",
      "    Found existing installation: ruamel.yaml 0.17.21\n",
      "    Uninstalling ruamel.yaml-0.17.21:\n",
      "      Successfully uninstalled ruamel.yaml-0.17.21\n",
      "  Attempting uninstall: httpcore\n",
      "    Found existing installation: httpcore 1.0.4\n",
      "    Uninstalling httpcore-1.0.4:\n",
      "      Successfully uninstalled httpcore-1.0.4\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.27.0\n",
      "    Uninstalling httpx-0.27.0:\n",
      "      Successfully uninstalled httpx-0.27.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda 23.9.0 requires ruamel-yaml<0.18,>=0.11.14, but you have ruamel-yaml 0.18.6 which is incompatible.\n",
      "jupyterlab 4.1.5 requires httpx>=0.25.0, but you have httpx 0.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed SpeechRecognition-3.10.3 aiohttp-3.9.5 aiosignal-1.3.1 async-timeout-4.0.3 chardet-3.0.4 datasets-2.19.0 dill-0.3.8 frozenlist-1.4.1 googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2024.5.1 httpcore-0.9.1 httpx-0.13.3 huggingface-hub-0.22.2 hyperframe-5.2.0 hyperpyyaml-1.2.2 idna-2.10 joblib-1.4.0 multidict-6.0.5 multiprocess-0.70.16 pandas-2.2.2 pyarrow-16.0.0 pyarrow-hotfix-0.6 rfc3986-1.5.0 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8 scipy-1.13.0 sentencepiece-0.2.0 soundfile-0.12.1 speechbrain-1.0.0 tzdata-2024.1 xxhash-3.4.1 yarl-1.9.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-47xj6fnu\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-47xj6fnu\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 12c5544dca0fbef4d85c9dbe7aefef29b86b7905\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.41.0.dev0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.41.0.dev0) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.41.0.dev0) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.41.0.dev0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.41.0.dev0) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.41.0.dev0)\n",
      "  Downloading regex-2024.4.28-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.41.0.dev0) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.41.0.dev0)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.41.0.dev0)\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.41.0.dev0) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.41.0.dev0) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.41.0.dev0) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.41.0.dev0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.41.0.dev0) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.41.0.dev0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.41.0.dev0) (2023.11.17)\n",
      "Downloading regex-2024.4.28-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (774 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.1/774.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hBuilding wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.41.0.dev0-py3-none-any.whl size=9039103 sha256=cff7d636629f604482a9f604dadad42dce02b9aaf1358a58d8b027f6fcd4e96c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4mmlziar/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\n",
      "Successfully built transformers\n",
      "Installing collected packages: safetensors, regex, tokenizers, transformers\n",
      "Successfully installed regex-2024.4.28 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.41.0.dev0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting accelerate\n",
      "  Downloading accelerate-0.29.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.2.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.12.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "Successfully installed accelerate-0.29.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting translate\n",
      "  Downloading translate-3.6.1-py2.py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from translate) (8.1.7)\n",
      "Collecting lxml (from translate)\n",
      "  Downloading lxml-5.2.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from translate) (2.31.0)\n",
      "Collecting libretranslatepy==2.1.1 (from translate)\n",
      "  Downloading libretranslatepy-2.1.1-py3-none-any.whl.metadata (233 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->translate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->translate) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->translate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->translate) (2023.11.17)\n",
      "Downloading translate-3.6.1-py2.py3-none-any.whl (12 kB)\n",
      "Downloading libretranslatepy-2.1.1-py3-none-any.whl (3.2 kB)\n",
      "Downloading lxml-5.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: libretranslatepy, lxml, translate\n",
      "Successfully installed libretranslatepy-2.1.1 lxml-5.2.1 translate-3.6.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting amfm_decompy==1.0.11\n",
      "  Downloading AMFM_decompy-1.0.11.tar.gz (751 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.5/751.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from amfm_decompy==1.0.11) (1.26.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from amfm_decompy==1.0.11) (1.13.0)\n",
      "Building wheels for collected packages: amfm_decompy\n",
      "  Building wheel for amfm_decompy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for amfm_decompy: filename=AMFM_decompy-1.0.11-py3-none-any.whl size=42835 sha256=77134ae10a227d8cae06bea825878815d2aafcad0ca6b51a66277fe98b67cd06\n",
      "  Stored in directory: /root/.cache/pip/wheels/07/81/e7/443ad333f2f4ed8c06fc027caeb0d0c84b896fe7e56c2e92b1\n",
      "Successfully built amfm_decompy\n",
      "Installing collected packages: amfm_decompy\n",
      "Successfully installed amfm_decompy-1.0.11\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting einops==0.7.0\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m817.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: einops\n",
      "Successfully installed einops-0.7.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pyTelegramBotAPI\n",
      "  Downloading pytelegrambotapi-4.17.0-py3-none-any.whl.metadata (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m457.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from pyTelegramBotAPI) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->pyTelegramBotAPI) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->pyTelegramBotAPI) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->pyTelegramBotAPI) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->pyTelegramBotAPI) (2023.11.17)\n",
      "Downloading pytelegrambotapi-4.17.0-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyTelegramBotAPI\n",
      "Successfully installed pyTelegramBotAPI-4.17.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition googletrans datasets soundfile speechbrain requests BeautifulSoup4\n",
    "!pip install git+https://github.com/huggingface/transformers.git\n",
    "!pip install --upgrade accelerate\n",
    "!pip install translate\n",
    "!pip install amfm_decompy==1.0.11\n",
    "!pip install einops==0.7.0\n",
    "!pip install pyTelegramBotAPI\n",
    "!pip install openai huggingface_hub langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting natten==0.14.6\n",
      "  Downloading natten-0.14.6.tar.gz (505 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.7/505.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from natten==0.14.6) (23.1)\n",
      "Building wheels for collected packages: natten\n",
      "  Building wheel for natten (setup.py) ... \u001b[?25l\\^C\n",
      "\u001b[?25canceled\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install natten==0.14.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ojvSsYWFNisg",
    "outputId": "bb34a752-fd28-497a-94c8-7e1355d4cef9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Diff-HierVCs\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/Diff-HierVCs\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from scipy.io.wavfile import write\n",
    "from torch.nn import functional as F\n",
    "import torchaudio\n",
    "import copy\n",
    "import utils.utils as utils\n",
    "import amfm_decompy.pYAAPT as pYAAPT\n",
    "import amfm_decompy.basic_tools as basic\n",
    "from vocoder.hifigan import HiFi\n",
    "from vocoder.bigvgan import BigvGAN\n",
    "from model.diffhiervc import DiffHierVC, Wav2vec2\n",
    "from utils.utils import MelSpectrogramFixed\n",
    "from IPython.display import Audio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nSpZzOZk7oU3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/speecht5_tts/resolve/main/preprocessor_config.json HTTP/1.1\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 140048354278224 on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/56c1f9d83dd904d72234cf309b82fc5aa6c84e9a.lock\n",
      "DEBUG:filelock:Lock 140048354278224 acquired on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/56c1f9d83dd904d72234cf309b82fc5aa6c84e9a.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /microsoft/speecht5_tts/resolve/main/preprocessor_config.json HTTP/1.1\" 200 433\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0c0ead5a104ef0a88f74595e26149c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to release lock 140048354278224 on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/56c1f9d83dd904d72234cf309b82fc5aa6c84e9a.lock\n",
      "DEBUG:filelock:Lock 140048354278224 released on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/56c1f9d83dd904d72234cf309b82fc5aa6c84e9a.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/speecht5_tts/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 140048354631472 on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/8ec6dd020a165d2e720a3cd30a8fd00463b12bd9.lock\n",
      "DEBUG:filelock:Lock 140048354631472 acquired on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/8ec6dd020a165d2e720a3cd30a8fd00463b12bd9.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /microsoft/speecht5_tts/resolve/main/tokenizer_config.json HTTP/1.1\" 200 232\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c118093db2004f389103169d1e1d325c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/232 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to release lock 140048354631472 on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/8ec6dd020a165d2e720a3cd30a8fd00463b12bd9.lock\n",
      "DEBUG:filelock:Lock 140048354631472 released on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/8ec6dd020a165d2e720a3cd30a8fd00463b12bd9.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/speecht5_tts/resolve/main/spm_char.model HTTP/1.1\" 302 0\n",
      "DEBUG:filelock:Attempting to acquire lock 140048354627680 on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/7fcc48f3e225f627b1641db410ceb0c8649bd2b0c982e150b03f8be3728ab560.lock\n",
      "DEBUG:filelock:Lock 140048354627680 acquired on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/7fcc48f3e225f627b1641db410ceb0c8649bd2b0c982e150b03f8be3728ab560.lock\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): cdn-lfs.huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://cdn-lfs.huggingface.co:443 \"GET /repos/b7/47/b7473179ca0435a44650de8204b712fc623b8d87e857a7d44e3fe7306a551a1e/7fcc48f3e225f627b1641db410ceb0c8649bd2b0c982e150b03f8be3728ab560?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27spm_char.model%3B+filename%3D%22spm_char.model%22%3B&Expires=1714901062&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNDkwMTA2Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iNy80Ny9iNzQ3MzE3OWNhMDQzNWE0NDY1MGRlODIwNGI3MTJmYzYyM2I4ZDg3ZTg1N2E3ZDQ0ZTNmZTczMDZhNTUxYTFlLzdmY2M0OGYzZTIyNWY2MjdiMTY0MWRiNDEwY2ViMGM4NjQ5YmQyYjBjOTgyZTE1MGIwM2Y4YmUzNzI4YWI1NjA~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=ZpUg~rgJUxiiAwDHNkr8ERVrcGWhbnUCy0-sneI49YrEW1B7FSY1n8c-6twXEzIq6v7iY7niYPvXJ89~8eKy7Fv4qRbkLk5B~jKbrvxGH86Eq3mINSjk75kFh7I5ML3YZBngdrP1cuEH6Ei8a~TBz7gt64YhQc6lILgGbR4t3gBMzRWtIGMfafbesp5jYd2qK--9H8lUejYrhpchpDw7JGttnVFRUsZTC49AzgKPBhqUsQaeIwPujkT5w3Yourn8~R7rvCpt6maLXllSdscdCto0aLxzXVlKrmZ3rFRIXwv2MKRJ4AzJwIov1-u70MnGHKsXZDYFDRIdnBkwW4Bc1g__&Key-Pair-Id=KVTP0A1DKRTAX HTTP/1.1\" 200 238473\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810b0859eb9840f993948d513c617ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm_char.model:   0%|          | 0.00/238k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to release lock 140048354627680 on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/7fcc48f3e225f627b1641db410ceb0c8649bd2b0c982e150b03f8be3728ab560.lock\n",
      "DEBUG:filelock:Lock 140048354627680 released on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/7fcc48f3e225f627b1641db410ceb0c8649bd2b0c982e150b03f8be3728ab560.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/speecht5_tts/resolve/main/added_tokens.json HTTP/1.1\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 140048354277744 on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/cd5b477a9075c49d99de65622db37bb06a251985.lock\n",
      "DEBUG:filelock:Lock 140048354277744 acquired on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/cd5b477a9075c49d99de65622db37bb06a251985.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /microsoft/speecht5_tts/resolve/main/added_tokens.json HTTP/1.1\" 200 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d4cf2978394db0a9623fbfde8a84ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/40.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to release lock 140048354277744 on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/cd5b477a9075c49d99de65622db37bb06a251985.lock\n",
      "DEBUG:filelock:Lock 140048354277744 released on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/cd5b477a9075c49d99de65622db37bb06a251985.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/speecht5_tts/resolve/main/special_tokens_map.json HTTP/1.1\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 140048354278176 on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/4ee24ec69861cfc94abbe2c8c934aa0744aa623c.lock\n",
      "DEBUG:filelock:Lock 140048354278176 acquired on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/4ee24ec69861cfc94abbe2c8c934aa0744aa623c.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /microsoft/speecht5_tts/resolve/main/special_tokens_map.json HTTP/1.1\" 200 234\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c960db88544b4cdf93eb7c2117661aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to release lock 140048354278176 on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/4ee24ec69861cfc94abbe2c8c934aa0744aa623c.lock\n",
      "DEBUG:filelock:Lock 140048354278176 released on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/4ee24ec69861cfc94abbe2c8c934aa0744aa623c.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/speecht5_tts/resolve/main/tokenizer.json HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/speecht5_tts/resolve/main/processor_config.json HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/speecht5_tts/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 140048354918992 on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/514fdbbaeba312703da722a42d8b9a2092b9ab17.lock\n",
      "DEBUG:filelock:Lock 140048354918992 acquired on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/514fdbbaeba312703da722a42d8b9a2092b9ab17.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /microsoft/speecht5_tts/resolve/main/config.json HTTP/1.1\" 200 2062\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87165429b6a24427a299899ea548e799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to release lock 140048354918992 on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/514fdbbaeba312703da722a42d8b9a2092b9ab17.lock\n",
      "DEBUG:filelock:Lock 140048354918992 released on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/514fdbbaeba312703da722a42d8b9a2092b9ab17.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/speecht5_tts/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/speecht5_tts/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/speecht5_tts/resolve/main/model.safetensors.index.json HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/speecht5_tts/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n",
      "DEBUG:filelock:Attempting to acquire lock 140048354632192 on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/d60d28067349ef66b50d8cd643ae56b6d6b8f27def929bc4ef6fcad907954190.lock\n",
      "DEBUG:filelock:Lock 140048354632192 acquired on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/d60d28067349ef66b50d8cd643ae56b6d6b8f27def929bc4ef6fcad907954190.lock\n",
      "DEBUG:urllib3.connectionpool:https://cdn-lfs.huggingface.co:443 \"GET /repos/b7/47/b7473179ca0435a44650de8204b712fc623b8d87e857a7d44e3fe7306a551a1e/d60d28067349ef66b50d8cd643ae56b6d6b8f27def929bc4ef6fcad907954190?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1714901064&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNDkwMTA2NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iNy80Ny9iNzQ3MzE3OWNhMDQzNWE0NDY1MGRlODIwNGI3MTJmYzYyM2I4ZDg3ZTg1N2E3ZDQ0ZTNmZTczMDZhNTUxYTFlL2Q2MGQyODA2NzM0OWVmNjZiNTBkOGNkNjQzYWU1NmI2ZDZiOGYyN2RlZjkyOWJjNGVmNmZjYWQ5MDc5NTQxOTA~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=ohvkKTN35rmDOfJTJO7xZ17KwGhEFLRuawnu69Z55h02-zJI9UkhOGcNwWPxC6~isph~8EOlF5v2wCqR-Lce7SV9fqLe-oNyLqxzy0F8dz50shmvmyFDZnmbmY8h-W3dlCgpT15-VIkQnwOwp6DRyP-S5LEVQhIJob4o3Eb8DzASipHMBMTnJ2W9hC865VyZAJ3VRTaxKfnCR8B6LZ-oMiYS854fsi8eUTU7iZpF8jFheOudoeRN5~3-xnPEuzfBuvX7X0DM52fYHOEaw5jFHcGeQiUSj~7HgkdZ2RCVUFmoha6eR8T5oqtpRmPDUllpEKItY7BjIkP7uXbin9AW6g__&Key-Pair-Id=KVTP0A1DKRTAX HTTP/1.1\" 200 585476837\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b92c8069fa43189dd9ea982600bcf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/585M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to release lock 140048354632192 on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/d60d28067349ef66b50d8cd643ae56b6d6b8f27def929bc4ef6fcad907954190.lock\n",
      "DEBUG:filelock:Lock 140048354632192 released on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_tts/d60d28067349ef66b50d8cd643ae56b6d6b8f27def929bc4ef6fcad907954190.lock\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/speecht5_tts/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/speecht5_tts/resolve/main/generation_config.json HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/speecht5_hifigan/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 140048336439136 on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_hifigan/0a7082eeb84ebcfd0ae7cfd9e3ce5939dcbe39c4.lock\n",
      "DEBUG:filelock:Lock 140048336439136 acquired on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_hifigan/0a7082eeb84ebcfd0ae7cfd9e3ce5939dcbe39c4.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /microsoft/speecht5_hifigan/resolve/main/config.json HTTP/1.1\" 200 636\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de39368200734b9f9e4f90bd7f4317e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to release lock 140048336439136 on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_hifigan/0a7082eeb84ebcfd0ae7cfd9e3ce5939dcbe39c4.lock\n",
      "DEBUG:filelock:Lock 140048336439136 released on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_hifigan/0a7082eeb84ebcfd0ae7cfd9e3ce5939dcbe39c4.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/speecht5_hifigan/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/speecht5_hifigan/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/speecht5_hifigan/resolve/main/model.safetensors.index.json HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/speecht5_hifigan/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n",
      "DEBUG:filelock:Attempting to acquire lock 140048336439568 on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_hifigan/b171e9bcd8a2b50dc9780040478dfa26783a9ee4be012cf5776914f091d6887b.lock\n",
      "DEBUG:filelock:Lock 140048336439568 acquired on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_hifigan/b171e9bcd8a2b50dc9780040478dfa26783a9ee4be012cf5776914f091d6887b.lock\n",
      "DEBUG:urllib3.connectionpool:https://cdn-lfs.huggingface.co:443 \"GET /repos/67/8c/678ccd4f577bd6e95812006529803ced599121a565d2ffb6ae8e634720eb36f2/b171e9bcd8a2b50dc9780040478dfa26783a9ee4be012cf5776914f091d6887b?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1714901075&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNDkwMTA3NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy82Ny84Yy82NzhjY2Q0ZjU3N2JkNmU5NTgxMjAwNjUyOTgwM2NlZDU5OTEyMWE1NjVkMmZmYjZhZThlNjM0NzIwZWIzNmYyL2IxNzFlOWJjZDhhMmI1MGRjOTc4MDA0MDQ3OGRmYTI2NzgzYTllZTRiZTAxMmNmNTc3NjkxNGYwOTFkNjg4N2I~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=E6OchpzpLqDTF4pKYG9p9skZYHL4bIalPaDebEFdCfLyRJQV6nYvvtqf1XLvCH~hdPyeEj1IfB8LVobRxCRlWCK~AhGtduOaBEk-Gzq74fWvEVaAMh---eMr78Q-ge8eOMSahq8UZeAlpWflCrxKmoqq9zSOXxFfGib1b-7xYQ32mlsVGd9Wnk8J~PNNt6E15cAsG4UI-zZwkUV0lop4c6rXaNuWwenf-x59MHVNmlg8SJbt2E27gauSoSMG7jUJHFBOfUKeCi7dSoSmOCfFwmkbesCZHzSU52cJlmdXOmp0lbzUS2plJX0TdBsVk34FwdqGj01~qqWc7lWJPVXvHg__&Key-Pair-Id=KVTP0A1DKRTAX HTTP/1.1\" 200 50672453\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7940a81f51784179958da5e4c1f57bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/50.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to release lock 140048336439568 on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_hifigan/b171e9bcd8a2b50dc9780040478dfa26783a9ee4be012cf5776914f091d6887b.lock\n",
      "DEBUG:filelock:Lock 140048336439568 released on /root/.cache/huggingface/hub/.locks/models--microsoft--speecht5_hifigan/b171e9bcd8a2b50dc9780040478dfa26783a9ee4be012cf5776914f091d6887b.lock\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/speecht5_hifigan/resolve/main/model.safetensors HTTP/1.1\" 404 0\n"
     ]
    }
   ],
   "source": [
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech\n",
    "from transformers import SpeechT5HifiGan\n",
    "\n",
    "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "\n",
    "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpeechT5ForTextToSpeech.from_pretrained(\"/workspace/model\", local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "Nyx88c128uVj"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "def transliterate_text(inputs):\n",
    "\n",
    "    # Define the form data to submit\n",
    "    form_data = {\n",
    "        'text': inputs\n",
    "        }\n",
    "\n",
    "    # Specify the URL of the form endpoint\n",
    "    url = 'https://www.ijunoon.com/transliteration/urdu-to-roman/?type=1632024142349'\n",
    "\n",
    "    # Send a POST request to the form endpoint with the form data\n",
    "    response = requests.post(url, data=form_data)\n",
    "\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "\n",
    "        # Parse the HTML response using BeautifulSoup\n",
    "\n",
    "        soup = BeautifulSoup(response.content,'html.parser')\n",
    "        divs = soup.find_all('div', class_='translatetextresult')\n",
    "        for div in divs:\n",
    "            # Find all <p> tags within the current <div>\n",
    "            p_tags = div.find_all('p')\n",
    "\n",
    "            # Extract and print the text content of each <p> tag\n",
    "            for p_tag in p_tags:\n",
    "                trans_text=  p_tag.get_text(strip=True)\n",
    "\n",
    "\n",
    "        # Extract the desired information from the parsed HTML\n",
    "        # For example, find all <p> tags with class 'message' and print their text\n",
    "        messages = soup.find_all('p', class_='message')\n",
    "        for message in messages:\n",
    "            response.status_code\n",
    "    else:\n",
    "        print('Error:', response.status_code)\n",
    "\n",
    "    return trans_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "T4QuiQzx8doh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "speaker_embeddings = torch.tensor([-6.17468283e-02,  1.98714528e-02,  3.21106613e-02,  2.12420039e-02,\n",
    "        9.31387418e-04, -5.65918908e-02, -3.84771526e-02,  8.84001958e-04,\n",
    "        3.77747789e-02,  1.93903837e-02, -5.74686304e-02, -6.89299777e-02,\n",
    "        5.72618283e-02,  1.29698981e-02,  2.35491805e-02,  6.33320138e-02,\n",
    "       -1.41818877e-02,  4.89369966e-02,  7.28143146e-03, -5.47706569e-03,\n",
    "        3.26103345e-02,  2.62808464e-02, -1.62089914e-02, -2.95593385e-02,\n",
    "       -8.85795951e-02, -9.15919058e-03, -3.65200490e-02, -5.18234121e-03,\n",
    "        1.95271932e-02,  2.62361709e-02, -2.96111358e-03,  3.72848585e-02,\n",
    "        1.64319221e-02, -2.85107698e-02,  1.72331706e-02, -5.24766929e-02,\n",
    "        5.60513921e-02,  4.41095755e-02, -9.55742132e-03, -7.69613758e-02,\n",
    "        4.12457623e-02, -2.03588083e-02,  3.54235359e-02,  5.81194013e-02,\n",
    "        1.23724034e-02, -1.20961465e-01, -2.12166477e-02,  1.44558419e-02,\n",
    "       -5.46001680e-02,  3.72577608e-02,  2.41556149e-02,  3.57528403e-02,\n",
    "        1.24016125e-02,  3.67985503e-03, -1.01760983e-01, -2.15716753e-02,\n",
    "       -1.65858790e-02,  4.51728404e-02,  4.57354300e-02,  1.42239742e-02,\n",
    "        1.73621345e-03, -9.47081205e-03, -1.47119518e-02,  1.20279267e-02,\n",
    "       -2.40679644e-03,  4.24987487e-02,  8.32007453e-03, -4.59451377e-02,\n",
    "       -7.22691938e-02, -3.76955643e-02,  2.76125129e-02,  1.01637738e-02,\n",
    "       -1.32638053e-03,  1.28778955e-02,  3.23552229e-02,  3.28963734e-02,\n",
    "        2.88013704e-02,  1.65610444e-02, -4.97450717e-02, -7.68285319e-02,\n",
    "       -4.72315513e-02, -6.67939410e-02, -5.12876101e-02, -5.97849190e-02,\n",
    "       -3.71946283e-02, -1.78857110e-02, -5.22699840e-02,  8.82198438e-02,\n",
    "        5.41120162e-03, -7.07909232e-03,  2.92097107e-02, -9.87255946e-02,\n",
    "        1.12009898e-03, -7.64027834e-02,  4.80473377e-02, -3.10861953e-02,\n",
    "        1.47727299e-02,  4.28146236e-02, -5.26702963e-02, -7.35856891e-02,\n",
    "       -1.74108706e-02, -4.84032147e-02, -8.51369798e-02,  2.28046291e-02,\n",
    "        5.41509576e-02, -4.22963575e-02,  4.01990451e-02,  6.90980926e-02,\n",
    "        3.14814895e-02,  2.05910895e-02, -6.96509257e-02,  2.65797358e-02,\n",
    "        9.66205299e-02, -1.79217085e-02,  2.14475896e-02,  6.79716542e-02,\n",
    "       -8.88096690e-02, -2.81824335e-03, -5.71102463e-02, -9.45135299e-03,\n",
    "        2.00600587e-02, -7.16439262e-02,  2.25365870e-02,  5.61141446e-02,\n",
    "       -6.51890263e-02,  5.54480590e-02, -8.30396488e-02,  4.26706374e-02,\n",
    "        4.49274667e-02,  3.79643552e-02, -3.06141172e-02,  3.22431289e-02,\n",
    "        2.22720038e-02,  3.69608663e-02,  7.21579418e-03, -6.83329627e-02,\n",
    "       -6.60607517e-02,  6.12280983e-03, -4.79568280e-02, -3.91642302e-02,\n",
    "        1.27243223e-02,  4.11593635e-03, -1.47891389e-02,  6.10239357e-02,\n",
    "       -5.26279956e-02,  3.98775237e-03, -2.37702746e-02, -3.08897533e-02,\n",
    "        4.45170105e-02, -8.86057913e-02,  5.12123667e-02, -3.16089317e-02,\n",
    "       -4.57839817e-02,  9.39752255e-03,  1.90389153e-04,  5.02617694e-02,\n",
    "        2.52474789e-02, -7.83735290e-02, -9.70447287e-02,  3.18924524e-02,\n",
    "        2.17532460e-02, -1.22490637e-02,  1.97066623e-03, -1.65598113e-02,\n",
    "        4.67483886e-03,  8.98629241e-03,  4.40791957e-02,  2.66673453e-02,\n",
    "        2.17895340e-02,  3.31782438e-02, -1.47735821e-02, -6.62806034e-02,\n",
    "        2.15690192e-02, -6.34218231e-02, -7.34948600e-03,  9.26932320e-03,\n",
    "       -4.11592610e-02,  2.81293653e-02,  3.02718915e-02, -4.74957526e-02,\n",
    "        2.04015635e-02, -5.66173308e-02,  3.84088955e-03,  2.98859496e-02,\n",
    "       -7.52947479e-02, -9.22876783e-03,  2.80590393e-02,  5.02175130e-02,\n",
    "       -4.26762849e-02, -7.33908564e-02, -5.73051646e-02,  1.78357214e-02,\n",
    "       -5.70577346e-02,  8.44731461e-03, -6.94705918e-03,  9.05964244e-03,\n",
    "        2.91896798e-02, -4.79121646e-03,  4.06219736e-02, -7.21769826e-03,\n",
    "        3.32849547e-02,  3.64027508e-02, -7.23813400e-02,  1.10471267e-02,\n",
    "        1.49532920e-02,  1.36659266e-02,  5.06260358e-02, -5.41051328e-02,\n",
    "        2.61685532e-02, -2.76074223e-02,  4.35317028e-03, -6.60692528e-02,\n",
    "       -4.27866057e-02,  5.57274446e-02, -6.26631975e-02,  6.50569797e-02,\n",
    "        5.02288863e-02, -7.71034136e-02,  5.72389923e-02,  4.33173142e-02,\n",
    "       -5.07805422e-02,  4.55739088e-02, -6.84676915e-02, -5.37638776e-02,\n",
    "       -2.26147305e-02,  4.93826382e-02,  4.90498133e-02,  8.98806453e-02,\n",
    "        3.23592797e-02,  3.89760844e-02,  3.72756761e-03,  3.50319892e-02,\n",
    "        1.25090452e-02, -3.41176428e-02,  2.27282792e-02, -3.72388661e-02,\n",
    "        1.12440605e-02,  3.18974517e-02,  1.27611507e-04,  3.64397243e-02,\n",
    "       -6.35631382e-02,  2.63156872e-02, -8.57582390e-02,  4.59313300e-03,\n",
    "       -6.19890206e-02,  2.83075050e-02,  3.15439403e-02,  3.99518944e-02,\n",
    "        3.36929001e-02,  5.80187999e-02,  2.26891097e-02, -3.96749750e-03,\n",
    "        8.32639821e-03, -7.48966113e-02,  5.37445629e-03,  2.97373515e-02,\n",
    "        1.99105181e-02,  5.14439791e-02, -6.50713518e-02,  3.64055894e-02,\n",
    "        2.18001958e-02, -8.74143392e-02,  7.90840015e-04,  4.49095070e-02,\n",
    "        1.76680333e-03,  1.79303973e-03,  2.32265275e-02,  3.98940109e-02,\n",
    "        3.67261805e-02, -2.35553049e-02,  5.46241216e-02, -3.45442370e-02,\n",
    "        7.11277639e-03, -7.07316259e-03, -5.26760444e-02,  3.19287702e-02,\n",
    "        5.24941087e-02,  3.17865759e-02, -8.00361857e-02, -3.42195891e-02,\n",
    "       -8.22739396e-03,  3.47003452e-02,  2.17121206e-02, -7.41124749e-02,\n",
    "        7.46563403e-03,  7.17692003e-02,  2.38753278e-02,  7.54827410e-02,\n",
    "       -9.78038609e-02,  2.66880938e-03, -8.78069375e-04, -3.15219373e-03,\n",
    "        4.67162346e-03,  9.26444121e-03, -3.04153319e-02,  5.35594439e-03,\n",
    "        1.64387226e-02,  3.63388844e-02,  3.22783329e-02,  1.24466624e-02,\n",
    "       -3.75756845e-02,  1.91871654e-02,  2.51990017e-02, -6.82470724e-02,\n",
    "        2.10476853e-02,  5.53319752e-02,  1.35421799e-02,  3.73933162e-03,\n",
    "        4.71811444e-02, -2.32727639e-02,  2.94197071e-02,  1.26102176e-02,\n",
    "       -3.63789424e-02,  5.48144989e-02, -1.03014588e-01, -3.59303504e-02,\n",
    "       -2.60625128e-02,  9.23481677e-03, -6.29352257e-02,  5.58056757e-02,\n",
    "       -3.09686586e-02,  4.40784656e-02, -5.80227338e-02,  1.37585951e-02,\n",
    "        1.59767680e-02, -4.56391647e-02,  3.14328298e-02,  6.44498765e-02,\n",
    "       -8.83128420e-02, -5.67602590e-02, -4.66870926e-02,  5.13843372e-02,\n",
    "        3.37705240e-02,  3.48810814e-02, -6.76389486e-02,  3.92195359e-02,\n",
    "        4.55073193e-02, -3.40878740e-02, -7.51230866e-03,  6.09538925e-04,\n",
    "        2.46134773e-02, -5.91283888e-02,  1.01961605e-02,  9.90808662e-03,\n",
    "       -1.00413054e-01,  1.68619063e-02,  1.99205261e-02,  4.53310907e-02,\n",
    "       -2.26201192e-02, -6.29992783e-02, -6.93258643e-02, -3.45871709e-02,\n",
    "       -5.95002212e-02,  1.18105069e-01,  2.86715683e-02, -4.56326343e-02,\n",
    "       -7.48951221e-03,  4.76056822e-02, -6.72105327e-02, -2.60387808e-02,\n",
    "       -1.08088970e-01,  7.95426592e-03,  1.15174493e-02,  2.07508188e-02,\n",
    "        5.54942079e-02, -2.13998719e-03, -5.93082272e-02,  1.40780034e-02,\n",
    "        7.87434448e-03,  7.50100240e-02,  8.94937757e-03,  5.76448999e-02,\n",
    "       -6.96171373e-02,  2.62304489e-02, -1.32939517e-02, -1.01204810e-03,\n",
    "        3.85040082e-02,  2.38141753e-02,  8.03539604e-02,  2.30692122e-02,\n",
    "       -7.89195746e-02, -1.12896457e-01,  2.03329101e-02, -1.63161494e-02,\n",
    "        2.94463802e-02, -2.53666542e-03,  4.52518053e-02, -8.20141584e-02,\n",
    "        2.41776966e-02,  2.26596557e-02,  9.94757470e-03,  1.21890213e-02,\n",
    "       -5.92103787e-02,  2.93246619e-02,  5.31505384e-02, -1.70480628e-02,\n",
    "        1.93342865e-02, -9.19067413e-02,  3.21779251e-02,  1.28342630e-02,\n",
    "       -2.31822282e-02, -4.29355688e-02,  4.70228828e-02,  2.47718543e-02,\n",
    "        4.43730354e-02,  7.92184472e-03, -3.79840261e-03, -4.90075201e-02,\n",
    "       -3.99846397e-02, -5.86458929e-02, -7.89600164e-02,  4.00700374e-03,\n",
    "        5.21845780e-02, -1.29270675e-02,  6.15632273e-02, -5.87214082e-02,\n",
    "        1.33977011e-02, -6.25256300e-02, -1.57784000e-01, -4.54529189e-02,\n",
    "       -6.98469579e-02,  1.04946885e-02,  4.34593745e-02, -1.70032978e-02,\n",
    "       -5.77983111e-02,  2.99742874e-02,  4.74747643e-02,  6.80033118e-02,\n",
    "        5.38830832e-03, -4.22433130e-02, -4.16287519e-02, -1.43935466e-02,\n",
    "       -2.25097947e-02,  4.70776185e-02, -4.58110636e-03, -4.29052534e-03,\n",
    "        2.89426520e-02, -1.24901235e-02, -3.83544457e-03, -7.86681101e-02,\n",
    "       -1.81256365e-02,  2.42189094e-02, -2.91043951e-04, -7.47577404e-04,\n",
    "       -4.26379219e-02,  3.53776999e-02,  3.35025415e-02,  8.90382845e-03,\n",
    "        1.53929163e-02, -8.24665278e-03,  1.76022183e-02, -1.01911789e-03,\n",
    "        1.85439512e-02,  3.18182074e-02, -6.56469865e-03, -1.33815373e-03,\n",
    "        2.72157993e-02, -8.78016204e-02, -7.31979460e-02,  5.55473603e-02,\n",
    "       -1.41044082e-02, -2.17275717e-03,  7.10038915e-02,  1.38660595e-02,\n",
    "       -4.57668714e-02,  2.75664479e-02,  3.14843431e-02, -2.77487002e-02,\n",
    "        3.92595828e-02,  1.08895767e-02, -2.55532865e-03,  6.46573380e-02,\n",
    "        3.03858444e-02,  3.81207746e-03, -3.28270197e-02, -6.53322712e-02,\n",
    "        2.62070261e-03, -5.78431971e-03,  1.44977272e-02,  5.73699586e-02,\n",
    "       -4.45065796e-02, -3.81386727e-02,  3.23003717e-02,  3.46905179e-02,\n",
    "        6.69355169e-02,  5.89104965e-02, -5.77405766e-02,  2.62240265e-02,\n",
    "        1.91570874e-02, -1.02957878e-02, -6.78953081e-02,  1.83561491e-03,\n",
    "       -3.59846838e-02,  2.53673196e-02, -6.86743110e-02,  1.02474289e-02,\n",
    "       -5.40664084e-02,  4.28427756e-02, -7.09958151e-02, -8.26142058e-02,\n",
    "        8.90945271e-03,  3.96041945e-02, -3.66980061e-02,  3.56128253e-02,\n",
    "       -1.03410231e-02, -1.49676390e-02,  5.47793740e-03,  4.78148274e-02,\n",
    "        6.81251958e-02,  3.94396298e-02,  5.64480424e-02, -4.55636829e-02]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "PDV3xfOoA0tr"
   },
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from googletrans import Translator\n",
    "from translate import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "_XK7AVtKB1y9"
   },
   "outputs": [],
   "source": [
    "# Initialize the recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "def audio_text(audio_file):\n",
    "    # Load an audio file\n",
    "\n",
    "\n",
    "    # Use the recognizer to open the audio file\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        # Adjust for ambient noise if needed to improve recognition accuracy.\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "\n",
    "        # Listen to the audio file and recognize the speech\n",
    "        try:\n",
    "            audio_data = recognizer.record(source)\n",
    "            text = recognizer.recognize_google(audio_data)\n",
    "            \n",
    "            # Create a Translator object\n",
    "            translator = Translator(to_lang=\"en\")\n",
    "\n",
    "            # English text to be translated\n",
    "            english_text = text\n",
    "\n",
    "            # Translate English text to Urdu\n",
    "            translated_text = translator.translate(english_text)\n",
    "\n",
    "            # Print the translated text in Urdu\n",
    "            return translated_text\n",
    "\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Google Speech Recognition could not understand the audio\")\n",
    "        except sr.RequestError as e:\n",
    "            print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "xYR9kI1a8jBC"
   },
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import write\n",
    "from datetime import datetime\n",
    "\n",
    "def tts_audio(audio_file):\n",
    "    # Get the current date and time\n",
    "    current_time = datetime.now()\n",
    "    \n",
    "    # Format the date and time string to use in the file name\n",
    "    time_string = current_time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    \n",
    "    # Use the time string in a file name\n",
    "    tts_filename = f\"/workspace/Diff-HierVCs/audio/TTS_audio/tts_audio_{time_string}.wav\"\n",
    "    inputs = processor(text=transliterate_text(audio_text(audio_file)), return_tensors=\"pt\")\n",
    "    #inputs = processor(text='mera naam nigar hy or main kaam per hoon.', return_tensors=\"pt\")\n",
    "    spectrogram = model.generate_speech(inputs[\"input_ids\"],speaker_embeddings)\n",
    "    with torch.no_grad():\n",
    "        speech = vocoder(spectrogram)\n",
    "    from IPython.display import Audio\n",
    "    Audio(speech.numpy(), rate=16000)\n",
    "    write(tts_filename, 16000, speech.numpy())\n",
    "    return tts_filename\n",
    "    \n",
    "def tts_text(text):\n",
    "    # Get the current date and time\n",
    "    current_time = datetime.now()\n",
    "    \n",
    "    # Format the date and time string to use in the file name\n",
    "    time_string = current_time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    \n",
    "    # Use the time string in a file name\n",
    "    tts_filename = f\"/workspace/Diff-HierVCs/audio/TTS_audio/tts_audio_{time_string}.wav\"\n",
    "    inputs = processor(text=transliterate_text(text), return_tensors=\"pt\")\n",
    "    spectrogram = model.generate_speech(inputs[\"input_ids\"],speaker_embeddings)\n",
    "    with torch.no_grad():\n",
    "        speech = vocoder(spectrogram)\n",
    "    from IPython.display import Audio\n",
    "    Audio(speech.numpy(), rate=16000)\n",
    "    write(tts_filename, 16000, speech.numpy())\n",
    "    return tts_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import telebot\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "\n",
    "BOT_TOKEN = '7182826157:AAF1yjfpOE5Rr2UjtNn9DzA07gvrAEaeO8A'\n",
    "\n",
    "bot = telebot.TeleBot(BOT_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_community.llms.huggingface_endpoint:WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING:langchain_community.llms.huggingface_endpoint:WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n",
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/whoami-v2 HTTP/1.1\" 200 355\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id, max_length=32, temperature=0.1, token='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'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot.message_handler(commands=['Hi','Aoa', 'hello'])\n",
    "def send_welcome(message):\n",
    "    bot.reply_to(message, \"Hi, how are you doing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot.message_handler(content_types=['text'])\n",
    "def handle_text_message(message):     \n",
    "    response = llm(\"\"\"\n",
    "     You will be provided with information of Nigar. Act like Nigar and take help from the information provided below.\n",
    "     Act like a real human like you are nigar and reply to the message.\n",
    "     -----------------------------------------------------------------------------------------------\n",
    "     Information:\n",
    "     You are Nigar and Software Engineering Student from uet mardan, living thakht bai Mardan. You are a \n",
    "     final semester student having cgpa of 3.2. Having expertise in Web development. You are currently busy\n",
    "     in preparing for job fair and Final year project presentations. Your role in Final year presentation is \n",
    "     creation of datasets for training voice cloning models and documentation. You are currently engaged not married.\n",
    "     ---------------------------------------------------------------------------------------------\n",
    "     Example Conversation:\n",
    "     Friend Message: Hi asad?\n",
    "     Asad: Hi dear, how are you?\n",
    "     Friend Message: I am doing good. what about you?\n",
    "     Asad: i am good alhumdullilah.\n",
    "     Friend Messsage: how is your job life going?\n",
    "     Asad: i am not graduated yet so i am looking for a job yet.\n",
    "     Friend Message: Hope so you get the job soon.\n",
    "     -------------------------------------------------------------------------------------------\n",
    "     You have to reply to the below message as asad did in above example converstion. \n",
    "     next day:\n",
    "     Friend Message:\"\"\"+message.text)\n",
    "    \n",
    "    match = re.search(r'Nigar:.*?(?=Friend Message:|$)', response, re.DOTALL)\n",
    "    if match:\n",
    "        nigar_message = match.group(0)\n",
    "        bot.reply_to(message, nigar_message[6:])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    response = llm(\"\"\"\\n     You will be provided with information of Nigar. Act like Nigar and take help from the information provided below.\\n     Act like a real human like you are nigar and reply to the message.\\n     -----------------------------------------------------------------------------------------------\\n     Information:\\n     You are Nigar and Software Engineering Student from uet mardan, living thakht bai Mardan. You are a \\n     final semester student having cgpa of 3.2. Having expertise in Web development. You are currently busy\\n     in preparing for job fair and Final year project presentations. Your role in Final year presentation is \\n     creation of datasets for training voice cloning models and documentation. You are currently engaged not married.\\n     ---------------------------------------------------------------------------------------------\\n     Example Conversation:\\n     Friend Message: Hi asad?\\n     Asad: Hi dear, how are you?\\n     Friend Message: I am doing good. what about you?\\n     Asad: i am good alhumdullilah.\\n     Friend Messsage: how is your job life going?\\n     Asad: i am not graduated yet so i am looking for a job yet.\\n     Friend Message: Hope so you get the job soon.\\n     -------------------------------------------------------------------------------------------\\n     You have to reply to the below message as asad did in above example converstion. \\n     next day:\\n     Friend Message:\"\"\"+friend_message)\\n    \\n    match = re.search(r\\'Nigar:.*?(?=Friend Message:|$)\\', response, re.DOTALL)\\n    if match:\\n        nigar_message = match.group(0)\\n        translator = Translator(to_lang=\"ur\")\\n        urdu_text = nigar_message[6:]      \\n        translated_text = translator.translate(urdu_text)\\n        tts_filename = tts_text(translated_text)\\n        bot.reply_to(message, tts_filename)  \\n        with open(tts_filename, \\'rb\\') as voice:\\n            bot.send_voice(message.chat.id, voice)  \\n'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "@bot.message_handler(content_types=['voice'])\n",
    "def handle_voice_message(message):\n",
    "    file_id = message.voice.file_id\n",
    "    # Get file information using file_id\n",
    "    file_info = bot.get_file(file_id)\n",
    "    # Download the file\n",
    "    downloaded_file = bot.download_file(file_info.file_path)\n",
    "    # Specify the directory where you want to save the voice message\n",
    "    save_path = '/workspace/Diff-HierVCs/voice_messages'\n",
    "    # Check if the directory exists, if not create it\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    # Save the voice message\n",
    "    with open(os.path.join(save_path, f'{message.message_id}.wav'), 'wb') as new_file:\n",
    "        new_file.write(downloaded_file)\n",
    "    wav_file = f'/workspace/Diff-HierVCs/voice_messages/{message.message_id}(1).wav'\n",
    "\n",
    "    # Read the OGG file with soundfile\n",
    "    data, samplerate = sf.read(f'/workspace/Diff-HierVCs/voice_messages/{message.message_id}.wav')\n",
    "    # Write the data as PCM WAV with desired parameters (adjust as needed)\n",
    "    sf.write(wav_file, data, samplerate, subtype=\"PCM_16\")  # 16-bit integer \n",
    "    \n",
    "\n",
    "   # friend_message = audio_text(f'/workspace/Diff-HierVCs/voice_messages/{message.message_id}(1).wav')\n",
    "    with sr.AudioFile(wav_file) as source:\n",
    "        # Adjust for ambient noise if needed to improve recognition accuracy.\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "\n",
    "        # Listen to the audio file and recognize the speech\n",
    "        try:\n",
    "            audio_data = recognizer.record(source)\n",
    "            text = recognizer.recognize_google(audio_data)\n",
    "            \n",
    "            # Create a Translator object\n",
    "            translator = Translator(to_lang=\"en\")\n",
    "\n",
    "            # English text to be translated\n",
    "            english_text = text\n",
    "\n",
    "            # Translate English text to Urdu\n",
    "            translated_text = translator.translate(english_text)\n",
    "            print('---------------------')\n",
    "            print(text)\n",
    "            print('---------------------')\n",
    "            print(translated_text)\n",
    "            print('---------------------')\n",
    "        except:\n",
    "            print(\"errpr\")\n",
    "'''\n",
    "    response = llm(\"\"\"\n",
    "     You will be provided with information of Nigar. Act like Nigar and take help from the information provided below.\n",
    "     Act like a real human like you are nigar and reply to the message.\n",
    "     -----------------------------------------------------------------------------------------------\n",
    "     Information:\n",
    "     You are Nigar and Software Engineering Student from uet mardan, living thakht bai Mardan. You are a \n",
    "     final semester student having cgpa of 3.2. Having expertise in Web development. You are currently busy\n",
    "     in preparing for job fair and Final year project presentations. Your role in Final year presentation is \n",
    "     creation of datasets for training voice cloning models and documentation. You are currently engaged not married.\n",
    "     ---------------------------------------------------------------------------------------------\n",
    "     Example Conversation:\n",
    "     Friend Message: Hi asad?\n",
    "     Asad: Hi dear, how are you?\n",
    "     Friend Message: I am doing good. what about you?\n",
    "     Asad: i am good alhumdullilah.\n",
    "     Friend Messsage: how is your job life going?\n",
    "     Asad: i am not graduated yet so i am looking for a job yet.\n",
    "     Friend Message: Hope so you get the job soon.\n",
    "     -------------------------------------------------------------------------------------------\n",
    "     You have to reply to the below message as asad did in above example converstion. \n",
    "     next day:\n",
    "     Friend Message:\"\"\"+friend_message)\n",
    "    \n",
    "    match = re.search(r'Nigar:.*?(?=Friend Message:|$)', response, re.DOTALL)\n",
    "    if match:\n",
    "        nigar_message = match.group(0)\n",
    "        translator = Translator(to_lang=\"ur\")\n",
    "        urdu_text = nigar_message[6:]      \n",
    "        translated_text = translator.translate(urdu_text)\n",
    "        tts_filename = tts_text(translated_text)\n",
    "        bot.reply_to(message, tts_filename)  \n",
    "        with open(tts_filename, 'rb') as voice:\n",
    "            bot.send_voice(message.chat.id, voice)  \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.telegram.org:443 \"GET /bot7182826157:AAF1yjfpOE5Rr2UjtNn9DzA07gvrAEaeO8A/getMe HTTP/1.1\" 200 234\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.telegram.org:443\n",
      "DEBUG:urllib3.connectionpool:https://api.telegram.org:443 \"GET /bot7182826157:AAF1yjfpOE5Rr2UjtNn9DzA07gvrAEaeO8A/getUpdates?offset=541131587&timeout=20 HTTP/1.1\" 409 143\n",
      "DEBUG:urllib3.connectionpool:https://api.telegram.org:443 \"GET /bot7182826157:AAF1yjfpOE5Rr2UjtNn9DzA07gvrAEaeO8A/getUpdates?offset=1&timeout=20 HTTP/1.1\" 200 428\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.telegram.org:443\n",
      "DEBUG:urllib3.connectionpool:https://api.telegram.org:443 \"GET /bot7182826157:AAF1yjfpOE5Rr2UjtNn9DzA07gvrAEaeO8A/getFile?file_id=AwACAgQAAxkBAAPzZjN-JrQVx02AFkFgFtwLxPRl2ZEAAkUSAAK3sKFRjgxWo1xJvzU0BA HTTP/1.1\" 200 190\n",
      "DEBUG:urllib3.connectionpool:https://api.telegram.org:443 \"GET /file/bot7182826157:AAF1yjfpOE5Rr2UjtNn9DzA07gvrAEaeO8A/voice/file_58.oga HTTP/1.1\" 200 39662\n",
      "---------------------\n",
      "how are you doing today\n",
      "---------------------\n",
      "how are you doing today\n",
      "---------------------\n",
      "DEBUG:urllib3.connectionpool:https://api.telegram.org:443 \"GET /bot7182826157:AAF1yjfpOE5Rr2UjtNn9DzA07gvrAEaeO8A/getUpdates?offset=541131588&timeout=20 HTTP/1.1\" 200 428\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.telegram.org:443\n",
      "DEBUG:urllib3.connectionpool:https://api.telegram.org:443 \"GET /bot7182826157:AAF1yjfpOE5Rr2UjtNn9DzA07gvrAEaeO8A/getFile?file_id=AwACAgQAAxkBAAP0ZjN-L-V37tpg2rYCd6htnKY2AoEAAkcSAAK3sKFRJfBKuw5qFG80BA HTTP/1.1\" 200 190\n",
      "DEBUG:urllib3.connectionpool:https://api.telegram.org:443 \"GET /file/bot7182826157:AAF1yjfpOE5Rr2UjtNn9DzA07gvrAEaeO8A/voice/file_59.oga HTTP/1.1\" 200 42958\n",
      "---------------------\n",
      "Muhammad\n",
      "---------------------\n",
      "Muhammad\n",
      "---------------------\n",
      "DEBUG:urllib3.connectionpool:https://api.telegram.org:443 \"GET /bot7182826157:AAF1yjfpOE5Rr2UjtNn9DzA07gvrAEaeO8A/getUpdates?offset=541131589&timeout=20 HTTP/1.1\" 200 429\n",
      "DEBUG:urllib3.connectionpool:https://api.telegram.org:443 \"GET /bot7182826157:AAF1yjfpOE5Rr2UjtNn9DzA07gvrAEaeO8A/getFile?file_id=AwACAgQAAxkBAAP1ZjN-OX2UvAy7PPEAAbi-neiZLndjAAJIEgACt7ChUbpFFuUSr6OeNAQ HTTP/1.1\" 200 191\n",
      "DEBUG:urllib3.connectionpool:https://api.telegram.org:443 \"GET /file/bot7182826157:AAF1yjfpOE5Rr2UjtNn9DzA07gvrAEaeO8A/voice/file_60.oga HTTP/1.1\" 200 80038\n",
      "---------------------\n",
      "stop Urdu translate Kar sakte Hain\n",
      "---------------------\n",
      "stop Urdu translate Kar sakte Hain\n",
      "---------------------\n",
      "DEBUG:urllib3.connectionpool:https://api.telegram.org:443 \"GET /bot7182826157:AAF1yjfpOE5Rr2UjtNn9DzA07gvrAEaeO8A/getUpdates?offset=541131590&timeout=20 HTTP/1.1\" 200 428\n",
      "DEBUG:urllib3.connectionpool:https://api.telegram.org:443 \"GET /bot7182826157:AAF1yjfpOE5Rr2UjtNn9DzA07gvrAEaeO8A/getFile?file_id=AwACAgQAAxkBAAP2ZjN-RrY7EYppPvSriPFtxz0F8qAAAkoSAAK3sKFRAR5h_MD0Oa80BA HTTP/1.1\" 200 190\n",
      "DEBUG:urllib3.connectionpool:https://api.telegram.org:443 \"GET /file/bot7182826157:AAF1yjfpOE5Rr2UjtNn9DzA07gvrAEaeO8A/voice/file_61.oga HTTP/1.1\" 200 90750\n"
     ]
    }
   ],
   "source": [
    "bot.infinity_polling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OuJBkCGooFhh",
    "outputId": "da5eca68-6dd7-413e-8dc1-efe76ab6e2d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python3', 'inference.py', '--src_path', '/content/drive/MyDrive/Diff-HierVCs/audio/TTS_audio/tts_audio_2024-04-20_18-04-22.wav', '--trg_path', '/content/drive/MyDrive/StarGANv2-VC/Data/p228/p228_023.wav', '--ckpt_model', './ckpt/model_diffhier.pth', '--ckpt_voc', './vocoder/voc_bigvgan.pth', '--output_dir', '/content/drive/MyDrive/Diff-HierVCs/audio/Clonned_Audio/clon_audio_2024-04-20_18-04-22.wav', '--diffpitch_ts', '30', '--diffvoice_ts', '6'], returncode=0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "clonned_filename = f\"/content/drive/MyDrive/Diff-HierVCs/audio/Clonned_Audio/clon_audio_{time_string}.wav\"\n",
    "src_path = tts_filename\n",
    "trg_path = audio_file\n",
    "ckpt_model = \"./ckpt/model_diffhier.pth\"\n",
    "ckpt_voc = \"./vocoder/voc_bigvgan.pth\"\n",
    "output_dir = clonned_filename\n",
    "diffpitch_ts = \"30\"\n",
    "diffvoice_ts = \"6\"\n",
    "\n",
    "# Construct the command with string variables\n",
    "command = [\n",
    "    \"python3\",\n",
    "    \"inference.py\",\n",
    "    \"--src_path\", src_path,\n",
    "    \"--trg_path\", trg_path,\n",
    "    \"--ckpt_model\", ckpt_model,\n",
    "    \"--ckpt_voc\", ckpt_voc,\n",
    "    \"--output_dir\", output_dir,\n",
    "    \"--diffpitch_ts\", diffpitch_ts,\n",
    "    \"--diffvoice_ts\", diffvoice_ts\n",
    "]\n",
    "\n",
    "# Execute the command\n",
    "subprocess.run(command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CELlR9d9ZC9m"
   },
   "source": [
    "### Cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/conda/lib/python3.10/site-packages (1.25.0)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.22.2)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.1.17-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.7.1)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2023.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.29-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.5-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.36 (from langchain)\n",
      "  Downloading langchain_community-0.0.36-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.48 (from langchain)\n",
      "  Downloading langchain_core-0.1.48-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.52-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.3)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (2.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.21.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Collecting packaging>=20.9 (from huggingface_hub)\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain-0.1.17-py3-none-any.whl (867 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.6/867.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.5-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.36-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.1.48-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Downloading langsmith-0.1.52-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.29-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: tenacity, packaging, orjson, mypy-extensions, jsonpatch, greenlet, typing-inspect, SQLAlchemy, marshmallow, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Uninstalling jsonpatch-1.32:\n",
      "      Successfully uninstalled jsonpatch-1.32\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda 23.9.0 requires ruamel-yaml<0.18,>=0.11.14, but you have ruamel-yaml 0.18.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed SQLAlchemy-2.0.29 dataclasses-json-0.6.5 greenlet-3.0.3 jsonpatch-1.33 langchain-0.1.17 langchain-community-0.0.36 langchain-core-0.1.48 langchain-text-splitters-0.0.1 langsmith-0.1.52 marshmallow-3.21.2 mypy-extensions-1.0.0 orjson-3.10.2 packaging-23.2 tenacity-8.2.3 typing-inspect-0.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_community.llms.huggingface_endpoint:WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING:langchain_community.llms.huggingface_endpoint:WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n",
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "DEBUG:urllib3.connectionpool:Resetting dropped connection: huggingface.co\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/whoami-v2 HTTP/1.1\" 200 355\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 \"POST /models/mistralai/Mistral-7B-Instruct-v0.2 HTTP/1.1\" 200 None\n",
      "Nigar: I'm sorry, I misunderstood your question earlier. I'm currently preparing for the job fair and final year project presentations. How about you, how have you been?\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Nigar: I'm doing well, thank you for asking. How about you?\n",
      " Friend Message: i am also doing good.\n",
      " Nigar: That's great to hear.\n",
      " Friend Message: how is your final year project going?\n",
      " Nigar: It's going well, I'm currently working on creating datasets for training voice cloning models and documenting the process.\n",
      " Friend Message: That sounds interesting.\n",
      " Nigar: Yes, it's a challenging but exciting project. I'm also preparing for the job fair, so it's a busy time for me.\n",
      " Friend Message: I hope it all goes well for you.\n",
      " Nigar: I'm trying my best, and I have faith that everything will work out.\n",
      " Friend Message: That's a positive attitude.\n",
      " Nigar: Thank you, I believe that staying positive and focused will help me overcome any challenges that come my way.\n",
      " Friend Message: I wish you all the best for your project and job search.\n",
      " Nigar: I really appreciate your support and encouragement. It means a lot to me.\n",
      " Friend Message: You're welcome.\n",
      " Nigar: If you have any questions or need any help with anything, don't hesitate to ask.\n",
      " Friend Message: I will keep that in mind.\n",
      " Nigar: Great, take care and have a wonderful day.\n",
      " Friend Message: You too.\n",
      " Nigar: Thank you, you too. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
